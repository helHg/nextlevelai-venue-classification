{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import os  # used for interacting with the operating system, such as file and directory manipulation\n",
    "import shutil  # used for high-level file operations like copying and removing files\n",
    "import random  # used for generating random numbers and making random selections\n",
    "import time  # used for time-related functions, such as adding delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_code\\\n",
    "# │\n",
    "# ├── project_comp6721_venv\\  # Virtual environment\n",
    "# │\n",
    "# ├── data\\\n",
    "# │   ├── original\\\n",
    "# │   │   └── places365_standard\\\n",
    "# │   │       ├── train\\  # Contains folders for each class\n",
    "# │   │       │   ├── airplane_cabin\\\n",
    "# │   │       │   ├── arena-hockey\\\n",
    "# │   │       │   ├── movie_theater-indoor\\\n",
    "# │   │       │   ├── staircase\\\n",
    "# │   │       │   └── supermarket\\\n",
    "# │   │       │   └── ...  # Other classes\n",
    "# │   │       └── val\\  # Validation images (not used in this script)\n",
    "# │   │\n",
    "# │   └── processed\\  # New dataset to be created\n",
    "# │       ├── train_val\\\n",
    "# │       │   ├── airplane_cabin\\\n",
    "# │       │   ├── hockey_arena\\\n",
    "# │       │   ├── movie_theater\\\n",
    "# │       │   ├── staircase\\\n",
    "# │       │   └── supermarket\\\n",
    "# │       │\n",
    "# │       └── test\\\n",
    "# │           ├── airplane_cabin\\\n",
    "# │           ├── hockey_arena\\\n",
    "# │           ├── movie_theater\\\n",
    "# │           ├── staircase\\\n",
    "# │           └── supermarket\\\n",
    "# │\n",
    "# └── notebooks\\  # Python code for data processing, model training, etc.\n",
    "#     ├── create_project_dataset.ipynb   \n",
    "#     └── comp6721_project.ipynb \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "NUM_IMAGES_PER_CLASS = 1000\n",
    "TEST_SPLIT_PERCENTAGE = 0.15\n",
    "TRAIN_VAL_SPLIT_PERCENTAGE = 1 - TEST_SPLIT_PERCENTAGE  # the rest is for training and validation\n",
    "BATCH_SIZE = 50  # number of images to copy at once\n",
    "RANDOM_SEED = 42  # seed for reproducibility\n",
    "CLASSES_ORIGINAL = ['airplane_cabin', 'arena-hockey', 'movie_theater-indoor', 'staircase', 'supermarket']\n",
    "CLASSES_NEW = ['airplane_cabin', 'hockey_arena', 'movie_theater', 'staircase', 'supermarket']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths of the original dataset and the new dataset\n",
    "ORIGINAL_DATASET_PATH = r'C:\\Users\\helen\\Documents\\Concordia University\\summer 2024\\COMP 6721\\project_code\\data\\original\\places365_standard\\train'\n",
    "NEW_DATASET_PATH = r'C:\\Users\\helen\\Documents\\Concordia University\\summer 2024\\COMP 6721\\project_code\\data\\processed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataset directory structure\n",
    "def create_directory_structure():\n",
    "    \"\"\"\n",
    "    Creates the directory structure for the new dataset, including directories for training/validation and testing sets for each class.\n",
    "\n",
    "    No inputs or outputs. The function creates directories in the file system.\n",
    "\n",
    "    It uses the global variables:\n",
    "    - CLASSES_NEW: List of new class names.\n",
    "    - NEW_DATASET_PATH: Path where the new dataset will be created.\n",
    "    \"\"\"\n",
    "    for split in ['train_val', 'test']:\n",
    "        for class_name in CLASSES_NEW:\n",
    "            os.makedirs(os.path.join(NEW_DATASET_PATH, split, class_name), exist_ok=True)\n",
    "            print(f\"Created directory: {os.path.join(NEW_DATASET_PATH, split, class_name)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to copy images to new directories\n",
    "def copy_images_in_batches(src_dir, dest_dir, file_list, batch_size):\n",
    "    \"\"\"\n",
    "    Copies images from the source directory to the destination directory in batches.\n",
    "\n",
    "    Inputs:\n",
    "    - src_dir: Source directory containing the original images.\n",
    "    - dest_dir: Destination directory where images will be copied.\n",
    "    - file_list: List of image filenames to be copied.\n",
    "    - batch_size: Number of images to copy in each batch.\n",
    "\n",
    "    No outputs. The function copies files and prints the status of each batch.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        batch = file_list[i:i + batch_size]\n",
    "        for file_name in batch:\n",
    "            src_file = os.path.join(src_dir, file_name)\n",
    "            dest_file = os.path.join(dest_dir, file_name)\n",
    "            shutil.copyfile(src_file, dest_file)\n",
    "            print(f\"Copied {src_file} to {dest_file}\")\n",
    "        time.sleep(0.5)  # Add a short delay to prevent overloading the file system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and distribute images\n",
    "def distribute_images():\n",
    "    \"\"\"\n",
    "    Extracts images from the original dataset, randomly selects a specified number of images per class,\n",
    "    and distributes them into training/validation and testing directories.\n",
    "\n",
    "    No inputs. Uses global constants and paths to locate the original dataset and create the new dataset.\n",
    "\n",
    "    No outputs. The function copies files and prints the status of the process.\n",
    "    \"\"\"\n",
    "    random.seed(RANDOM_SEED)  # Set the seed for reproducibility\n",
    "    \n",
    "    for original_class, new_class in zip(CLASSES_ORIGINAL, CLASSES_NEW):\n",
    "        class_path = os.path.join(ORIGINAL_DATASET_PATH, original_class)\n",
    "        if not os.path.exists(class_path):\n",
    "            print(f\"Directory does not exist: {class_path}\")\n",
    "            continue\n",
    "\n",
    "        all_images = os.listdir(class_path)\n",
    "        if len(all_images) < NUM_IMAGES_PER_CLASS:\n",
    "            print(f\"Not enough images in {class_path}\")\n",
    "            continue\n",
    "\n",
    "        # select images randomly from the entire range of the original dataset\n",
    "        selected_images = random.sample(all_images, NUM_IMAGES_PER_CLASS)\n",
    "        \n",
    "        # calculate number of images for each split\n",
    "        num_test_images = int(NUM_IMAGES_PER_CLASS * TEST_SPLIT_PERCENTAGE)\n",
    "        num_train_val_images = NUM_IMAGES_PER_CLASS - num_test_images\n",
    "        \n",
    "        # split the selected images into train_val and test sets\n",
    "        train_val_images = selected_images[:num_train_val_images]\n",
    "        test_images = selected_images[num_train_val_images:]\n",
    "        \n",
    "        # copy images to the new dataset structure\n",
    "        copy_images_in_batches(class_path, os.path.join(NEW_DATASET_PATH, 'train_val', new_class), train_val_images, BATCH_SIZE)\n",
    "        copy_images_in_batches(class_path, os.path.join(NEW_DATASET_PATH, 'test', new_class), test_images, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the creation of the new dataset. \n",
    "    It creates the directory structure and distributes images.\n",
    "    \"\"\"\n",
    "    create_directory_structure()\n",
    "    distribute_images()    \n",
    "    print(\"New dataset created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
