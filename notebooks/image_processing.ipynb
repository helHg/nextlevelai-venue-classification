{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Huge\\textbf{Image Processing}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import os  #  directory and file operations\n",
    "import shutil  #  copying files\n",
    "import  time  #  adding delays\n",
    "\n",
    "# installed library imports\n",
    "from sklearn.model_selection import train_test_split  #  splitting datasets\n",
    "from PIL import Image  #  image processing\n",
    "import torchvision.transforms as transforms  #  data augmentation\n",
    "import numpy as np  #  numerical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PROJECT_DATASET_DIR = r'C:\\Users\\helen\\Documents\\Concordia University\\summer 2024\\COMP 6721\\project_code\\data\\project_dataset'\n",
    "TRAIN_VAL_DIR = os.path.join(PROJECT_DATASET_DIR, 'train_val')\n",
    "TEST_DIR = os.path.join(PROJECT_DATASET_DIR, 'test')\n",
    "\n",
    "TRAIN_DIR = os.path.join(PROJECT_DATASET_DIR, 'train')  # new directory\n",
    "VALIDATION_DIR = os.path.join(PROJECT_DATASET_DIR, 'validation')  # new directory\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "VALIDATION_SPLIT = 15 / 85  # train_val is 85% of the total dataset, we want the validation set to be 15% of the total dataset\n",
    "CLASSES = ['airplane_cabin', 'hockey_arena', 'movie_theater', 'staircase', 'supermarket']\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We aim to obtain the following structure:\n",
    "\n",
    "# project_code\\\n",
    "# │\n",
    "# ├── data\\\n",
    "# │   └── project_dataset\\  \n",
    "# │       ├── train_val\\\n",
    "# │       │   ├── airplane_cabin\\\n",
    "# │       │   ├── hockey_arena\\\n",
    "# │       │   ├── movie_theater\\\n",
    "# │       │   ├── staircase\\\n",
    "# │       │   └── supermarket\\\n",
    "# │       │\n",
    "# │       ├── test\\  ---> normalized data (750 images in total)\n",
    "# │       │   ├── airplane_cabin\\  ---> 150 images \n",
    "# │       │   ├── hockey_arena\\  ---> 150 images \n",
    "# │       │   ├── movie_theater\\  ---> 150 images\n",
    "# │       │   ├── staircase\\  ---> 150 images \n",
    "# │       │   └── supermarket\\  ---> 150 images \n",
    "# │       │\n",
    "# │       ├── training\\  ---> normalized and augmented data (14,000 images in total)\n",
    "# │       │   ├── airplane_cabin\\  ---> 4 x 700 = 2800 images\n",
    "# │       │   ├── hockey_arena\\  ---> 2800 images\n",
    "# │       │   ├── movie_theater\\  ---> 2800 images\n",
    "# │       │   ├── staircase\\  ---> 2800 images\n",
    "# │       │   └── supermarket\\  ---> 2800 images\n",
    "# │       │\n",
    "# │       └── validation\\  ---> normalized data (750 images in total)\n",
    "# │           ├── airplane_cabin\\  ---> 150 images\n",
    "# │           ├── hockey_arena\\  ---> 150 images\n",
    "# │           ├── movie_theater\\  ---> 150 images\n",
    "# │           ├── staircase\\  ---> 150 images\n",
    "# │           └── supermarket\\  ---> 150 images\n",
    "# │\n",
    "# └── notebooks\\  # Python code for data processing, model training, etc.\n",
    "#     ├── create_project_dataset.ipynb   \n",
    "#     ├── image_processing.ipynb  \n",
    "#     └── ...  # other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Sets Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new directory for train set and a new directory for validation set\n",
    "def create_directories():\n",
    "    \"\"\"\n",
    "    Create directories for processed data.\n",
    "    \n",
    "    No inputs or outputs. This function creates train and validation directories for each class.\n",
    "    \"\"\"\n",
    "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(VALIDATION_DIR, exist_ok=True)\n",
    "    for class_name in CLASSES:\n",
    "        os.makedirs(os.path.join(TRAIN_DIR, class_name), exist_ok=True)\n",
    "        os.makedirs(os.path.join(VALIDATION_DIR, class_name), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy images from the train_val directory to the new train and val directories\n",
    "def copy_images_in_batches(src_dir, dest_dir, file_list, batch_size):\n",
    "    \"\"\"\n",
    "    Copy images from the source directory to the destination directory in batches.\n",
    "    Include a short delay to prevent overloading the file system.\n",
    "\n",
    "    Inputs:\n",
    "    - src_dir: Source directory containing the original images.\n",
    "    - dest_dir: Destination directory where images will be copied.\n",
    "    - file_list: List of image filenames to be copied.\n",
    "    - batch_size: Number of images to copy in each batch.\n",
    "\n",
    "    No outputs. The function copies files and prints the status of each batch.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        batch = file_list[i:i + batch_size]\n",
    "        for file_name in batch:\n",
    "            src_file = os.path.join(src_dir, file_name)\n",
    "            dest_file = os.path.join(dest_dir, file_name)\n",
    "            shutil.copyfile(src_file, dest_file)\n",
    "            print(f\"Copied {src_file} to {dest_file}\")\n",
    "        time.sleep(0.5)  # add a short delay to prevent overloading the file system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribute the images in train and validation sets\n",
    "def split_train_val():\n",
    "    \"\"\"\n",
    "    Split the data in train_val directory into training and validation sets.\n",
    "\n",
    "    No inputs or outputs. This function splits the images and moves them to their respective directories.\n",
    "    \"\"\"\n",
    "    for class_name in CLASSES:\n",
    "        class_dir = os.path.join(TRAIN_VAL_DIR, class_name)\n",
    "        images = os.listdir(class_dir)\n",
    "        train_images, val_images = train_test_split(images, test_size=VALIDATION_SPLIT, random_state=RANDOM_SEED)\n",
    "\n",
    "        # copy training images in batches\n",
    "        copy_images_in_batches(class_dir, os.path.join(TRAIN_DIR, class_name), train_images, BATCH_SIZE)\n",
    "\n",
    "        # copy validation images in batches\n",
    "        copy_images_in_batches(class_dir, os.path.join(VALIDATION_DIR, class_name), val_images, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Validation, and Testing Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize both training and validation images\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Resize (to 256x256) and normalize the image using PyTorch transforms.\n",
    "    \n",
    "    Inputs:\n",
    "    - image: PIL Image object.\n",
    "    \n",
    "    Output:\n",
    "    - Normalized image as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),  # converts image to PyTorch tensor and scales pixel values to [0, 1]\n",
    "    ])\n",
    "    return transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images_in_directory(directory):\n",
    "    \"\"\"\n",
    "    Normalize all images in the specified directory.\n",
    "    Normalized images are converted back to PIL images and overwrite the original ones.\n",
    "    \n",
    "    Inputs:\n",
    "    - directory: Path to the directory containing images.\n",
    "    \n",
    "    No outputs. This function normalizes images and saves them back as PIL images.\n",
    "    \"\"\"\n",
    "    for class_name in CLASSES:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            image = Image.open(img_path)\n",
    "            normalized_image = normalize_image(image)\n",
    "            normalized_image_pil = transforms.ToPILImage()(normalized_image)\n",
    "            normalized_image_pil.save(img_path)  # overwrite the original image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only augment training images\n",
    "def augment_image(image):\n",
    "    \"\"\"\n",
    "    Apply combined augmentation techniques (rotation, flipping, brightness enhancement) to the image using PyTorch transforms.\n",
    "    Each original image generates three additional augmented images, increasing the dataset size.\n",
    "    \n",
    "    Inputs:\n",
    "    - image: PIL Image object.\n",
    "    \n",
    "    Outputs:\n",
    "    - List of augmented images as PIL Image objects.\n",
    "    \"\"\"\n",
    "    # define the transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(15),  # randomly rotate the image by up to 15 degrees\n",
    "        transforms.RandomHorizontalFlip(),  # randomly flip the image horizontally with a probability of 0.5\n",
    "        transforms.ColorJitter(brightness=1.5)  # randomly change the brightness of the image\n",
    "    ])\n",
    "    \n",
    "    # apply the transformations directly to the PIL image\n",
    "    augmented_images = [transform(image) for _ in range(3)]  # give 3 augmentations\n",
    "    return augmented_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images_in_directory(directory):\n",
    "    \"\"\"\n",
    "    Apply augmentation to all images in the specified (training) directory.\n",
    "    Augmented images are directly saved into the training directory.\n",
    "    \n",
    "    Inputs:\n",
    "    - directory: Path to the directory containing images.\n",
    "    \n",
    "    No outputs. This function augments images and saves them in the same directory.\n",
    "    \"\"\"\n",
    "    for class_name in CLASSES:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            image = Image.open(img_path)\n",
    "            augmented_images = augment_image(image)\n",
    "            for i, aug_image in enumerate(augmented_images):\n",
    "                aug_image_path = os.path.join(class_dir, f\"{os.path.splitext(img_name)[0]}_aug_{i}.jpg\")\n",
    "                aug_image.save(aug_image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation directories\n",
    "create_directories()\n",
    "print(\"train and validation directories created sucessfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribute images into training and validation directories\n",
    "split_train_val()\n",
    "print(\"train and validation data split successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training and validation images\n",
    "\n",
    "normalize_images_in_directory(TRAIN_DIR)\n",
    "print(\"training data normalized successfully!\")\n",
    "\n",
    "normalize_images_in_directory(VALIDATION_DIR)\n",
    "print(\"validation data normalized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize testing images\n",
    "normalize_images_in_directory(TRAIN_DIR)\n",
    "print(\"testing data normalized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the training images\n",
    "augment_images_in_directory(TRAIN_DIR)\n",
    "print(\"training data augmented successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
